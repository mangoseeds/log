{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xzH-3s9NKG-M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "diary = pd.read_csv(\"C:/Users/user/Documents/EWHA/log/log/modelling/diary.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "b53-B2gNKNJ2",
    "outputId": "81d2491a-ca65-4aa0-b152-5aa8e347c559"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일기</th>\n",
       "      <th>요약</th>\n",
       "      <th>해시태그</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...</td>\n",
       "      <td>오랜 기간 준비해온 시험을 보러 다녀왔어요. 불안과 긴장 속에서도 최선을 다해 시험...</td>\n",
       "      <td>#시험 #노력 #성취감 #안도감 #자부심</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...</td>\n",
       "      <td>오랜 기간 준비해온 시험을 보러 다녀왔어요. 시험 중에는 최대한 집중하고 최선을 다...</td>\n",
       "      <td>#시험 #노력 #집중 #결과기다림 #휴식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...</td>\n",
       "      <td>오랜 기간 준비한 시험을 보러 다녀왔어요. 시험 중에는 최선을 다해 문제를 해결하려...</td>\n",
       "      <td>#시험 #노력 #문제해결 #결과기다림 #휴식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>오늘은 내가 사랑하는 사람과 소중한 시간을 보내러 다녀왔어. 그 동안 서로 바쁘게 ...</td>\n",
       "      <td>사랑하는 사람과 함께한 소중한 시간이었어요. 서로의 이야기를 나누고 응원해주며 사랑...</td>\n",
       "      <td>#사랑하는사람과함께 #소중한시간 #서로의이해 #사랑과애정 #감사함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오늘은 내가 사랑하는 사람과 소중한 시간을 보내러 다녀왔어. 그 동안 서로 바쁘게 ...</td>\n",
       "      <td>사랑하는 사람과 함께한 소중한 시간이었어요. 서로의 이야기를 나누고 사랑을 나눌 수...</td>\n",
       "      <td>#사랑하는사람과함께 #소중한시간 #서로의이야기 #배려와사랑 #행복함</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  일기  \\\n",
       "0  오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...   \n",
       "1  오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...   \n",
       "2  오늘은 오랜 기간 준비해온 시험을 보러 다녀왔어. 시험 전날부터 긴장과 불안이 가시...   \n",
       "3  오늘은 내가 사랑하는 사람과 소중한 시간을 보내러 다녀왔어. 그 동안 서로 바쁘게 ...   \n",
       "4  오늘은 내가 사랑하는 사람과 소중한 시간을 보내러 다녀왔어. 그 동안 서로 바쁘게 ...   \n",
       "\n",
       "                                                  요약  \\\n",
       "0  오랜 기간 준비해온 시험을 보러 다녀왔어요. 불안과 긴장 속에서도 최선을 다해 시험...   \n",
       "1  오랜 기간 준비해온 시험을 보러 다녀왔어요. 시험 중에는 최대한 집중하고 최선을 다...   \n",
       "2  오랜 기간 준비한 시험을 보러 다녀왔어요. 시험 중에는 최선을 다해 문제를 해결하려...   \n",
       "3  사랑하는 사람과 함께한 소중한 시간이었어요. 서로의 이야기를 나누고 응원해주며 사랑...   \n",
       "4  사랑하는 사람과 함께한 소중한 시간이었어요. 서로의 이야기를 나누고 사랑을 나눌 수...   \n",
       "\n",
       "                                       해시태그  \n",
       "0                  #시험 #노력 #성취감 #안도감 #자부심    \n",
       "1                  #시험 #노력 #집중 #결과기다림 #휴식    \n",
       "2                  #시험 #노력 #문제해결 #결과기다림 #휴식  \n",
       "3    #사랑하는사람과함께 #소중한시간 #서로의이해 #사랑과애정 #감사함    \n",
       "4   #사랑하는사람과함께 #소중한시간 #서로의이야기 #배려와사랑 #행복함    "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일기</th>\n",
       "      <th>요약</th>\n",
       "      <th>해시태그</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>오늘은 힘들고 좌절감이 가득한 날을 보내며 부정적인 감정에 휩싸인 사람으로서의 날이...</td>\n",
       "      <td>힘들고 좌절감에 휩싸인 날을 보내며 부정적인 감정을 느낀 특별한 경험을 한 날이었어.</td>\n",
       "      <td>#힘들고좌절한날 #상실감과무력감 #희망을잃지말자 #자아격려 #힘과용기를찾아서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>오늘은 우울하고 힘들어서 어둠에 휩싸인 날을 보내며 부정적인 감정이 가득한 사람으로...</td>\n",
       "      <td>우울하고 어둠에 휩싸인 날을 보내며 부정적인 감정을 느낀 특별한 경험을 한 날이었어.</td>\n",
       "      <td>#우울하고힘든날 #어둠에휩싸인감정 #감정수용 #자신을위로하며 #강함과빛을찾아서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>오늘은 나와 함께 소중한 시간을 보낸 반려동물과의 특별한 일상을 기록하고자 하는 사...</td>\n",
       "      <td>반려동물과 함께하는 특별한 일상을 기록하며 사랑과 행복을 느낀 특별한 경험을 한 날...</td>\n",
       "      <td>#고양이 #소중한시간 #사랑과행복 #힐링과위로 #행복한일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>오늘은 나의 반려동물인 강아지와 함께한 특별한 하루를 기록하고자 하는 사람으로서의 ...</td>\n",
       "      <td>반려동물과 함께 특별한 일상을 기록하며 즐거움과 행복을 느낀 특별한 경험을 한 날이었어.</td>\n",
       "      <td>#강아지 #즐거움과행복 #충실한친구 #사랑스러운모습 #행복한일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>오늘도 햄스터와 함께 놀이를 하고 음식을 나누며 서로의 애정을 나누었어. 작은 몸짓...</td>\n",
       "      <td>반려동물과 함께 특별한 일상을 기록하며 귀여움과 즐거움을 느낀 특별한 경험을 한 날...</td>\n",
       "      <td>#햄스터 #귀여움과즐거움 #작은행복 #사랑과관심 #행복한일상</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    일기  \\\n",
       "211  오늘은 힘들고 좌절감이 가득한 날을 보내며 부정적인 감정에 휩싸인 사람으로서의 날이...   \n",
       "212  오늘은 우울하고 힘들어서 어둠에 휩싸인 날을 보내며 부정적인 감정이 가득한 사람으로...   \n",
       "213  오늘은 나와 함께 소중한 시간을 보낸 반려동물과의 특별한 일상을 기록하고자 하는 사...   \n",
       "214  오늘은 나의 반려동물인 강아지와 함께한 특별한 하루를 기록하고자 하는 사람으로서의 ...   \n",
       "215  오늘도 햄스터와 함께 놀이를 하고 음식을 나누며 서로의 애정을 나누었어. 작은 몸짓...   \n",
       "\n",
       "                                                    요약  \\\n",
       "211    힘들고 좌절감에 휩싸인 날을 보내며 부정적인 감정을 느낀 특별한 경험을 한 날이었어.   \n",
       "212    우울하고 어둠에 휩싸인 날을 보내며 부정적인 감정을 느낀 특별한 경험을 한 날이었어.   \n",
       "213  반려동물과 함께하는 특별한 일상을 기록하며 사랑과 행복을 느낀 특별한 경험을 한 날...   \n",
       "214  반려동물과 함께 특별한 일상을 기록하며 즐거움과 행복을 느낀 특별한 경험을 한 날이었어.   \n",
       "215  반려동물과 함께 특별한 일상을 기록하며 귀여움과 즐거움을 느낀 특별한 경험을 한 날...   \n",
       "\n",
       "                                            해시태그  \n",
       "211   #힘들고좌절한날 #상실감과무력감 #희망을잃지말자 #자아격려 #힘과용기를찾아서  \n",
       "212  #우울하고힘든날 #어둠에휩싸인감정 #감정수용 #자신을위로하며 #강함과빛을찾아서  \n",
       "213             #고양이 #소중한시간 #사랑과행복 #힐링과위로 #행복한일상  \n",
       "214          #강아지 #즐거움과행복 #충실한친구 #사랑스러운모습 #행복한일상  \n",
       "215            #햄스터 #귀여움과즐거움 #작은행복 #사랑과관심 #행복한일상  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diary.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3qABNsMLqai"
   },
   "source": [
    "## HashTag Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbB6rTmXLgMo",
    "outputId": "c2d15109-83ae-46ce-9964-725c151b2e1a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\EWHA\\log\\log\\web\\flask-server\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from tokenizers import Tokenizer\n",
    "from typing import Dict, List, Optional\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display\n",
    "from typing import Dict\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C8Sr3OsuLtQt",
    "outputId": "20ea1074-92f8-4a48-faad-9150ea2d09f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gogamza/kobart-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYZVojrOMehT",
    "outputId": "7c7cc19f-3321-4e43-8742-147456dc0db3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max input\n",
    "max(diary['요약'].map(lambda x: len(x)).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNgWlGJYQAn2",
    "outputId": "a8ad71c8-de89-4a8c-e380-e7b7d25904e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max output\n",
    "max(diary['해시태그'].map(lambda x: len(x)).to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I6odSCniL-CL"
   },
   "outputs": [],
   "source": [
    "class HashTagMakerDataset(Dataset):\n",
    "  def __init__(self,\n",
    "               df: pd.DataFrame,\n",
    "               tokenizer: Tokenizer\n",
    "               ):\n",
    "    self.df = df\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    row = self.df.iloc[index, :]\n",
    "    text1 = row[1]\n",
    "    text2 = row[2]\n",
    "\n",
    "    encoder_text = text1\n",
    "    decoder_text = text2\n",
    "    model_inputs = self.tokenizer(encoder_text, max_length=181, truncation=True)\n",
    "\n",
    "    with self.tokenizer.as_target_tokenizer():\n",
    "      labels = tokenizer(decoder_text, max_length=43, truncation=True)\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    del model_inputs['token_type_ids']\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jSzdjwfpL-Ep",
    "outputId": "3b5b5bcd-16cd-49fa-a0ee-36507a8819c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194 22\n"
     ]
    }
   ],
   "source": [
    "# Train, Test split - 현재는 이 과정 skip\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(diary, test_size=0.1, random_state=42) # train, test 분리\n",
    "print(len(df_train), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmYb2WA6L-Gz",
    "outputId": "71437e3a-a4e3-4ac9-b10c-0444303b7117"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = HashTagMakerDataset(df_train, tokenizer)\n",
    "test_dataset = HashTagMakerDataset(df_test, tokenizer)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cDf0cqe2L-JO"
   },
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/user/Documents/EWHA/log/log/modelling/\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=24,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_steps=500,\n",
    "    save_steps=1000,\n",
    "    warmup_steps=300,\n",
    "    prediction_loss_only=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=3\n",
    "    )\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtqmpqLahV1i",
    "outputId": "05675047-ebdd-4892-8178-71e836c8f140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 사용 가능 -> 가장 빠른 번호 GPU, GPU 사용 불가 -> CPU 자동 지정 예시\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jY32wuoBimGX",
    "outputId": "0166d989-2c78-4090-ed4e-3f86d068b4ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "w1OSchx8Sylq",
    "outputId": "e34f7a1f-f056-40d1-b17e-a475fffbd6cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\EWHA\\log\\log\\web\\flask-server\\venv\\Lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19472\\1660611669.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text1 = row[1]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_19472\\1660611669.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text2 = row[2]\n",
      "C:\\Users\\user\\Documents\\EWHA\\log\\log\\web\\flask-server\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='312' max='312' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [312/312 00:51, Epoch 24/24]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=312, training_loss=2.094893039801182, metrics={'train_runtime': 52.4237, 'train_samples_per_second': 88.815, 'train_steps_per_second': 5.952, 'total_flos': 132796313395200.0, 'train_loss': 2.094893039801182, 'epoch': 24.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfcveaeFS3qA"
   },
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "id": "MJlqQKs6TW2A",
    "outputId": "075ee987-8f5f-4933-98eb-b3ff379a45e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1712\\1660611669.py:14: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text1 = row[1]\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1712\\1660611669.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text2 = row[2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate(eval_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x59DTz83TgmE",
    "outputId": "81651615-4241-41fa-fee2-19d75cddf4a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5847703218460083,\n",
       " 'eval_runtime': 0.082,\n",
       " 'eval_samples_per_second': 268.417,\n",
       " 'eval_steps_per_second': 24.402,\n",
       " 'epoch': 24.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99Igisp0TW4g",
    "outputId": "0dae9d8c-d193-40b9-ca40-2376433489a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 손실: 1.5847703218460083\n"
     ]
    }
   ],
   "source": [
    "loss = evaluation_results[\"eval_loss\"]\n",
    "print(\"평가 손실:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTIL89OWfFRN",
    "outputId": "17d7489f-420b-4e72-e88e-29da3f0f86d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\EWHA\\log\\log\\web\\flask-server\\venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 명절을 맞아 고향에 돌아와 가족과 함께 보낸 특별하고 따뜻한 하루였다. 가족의 사랑과 고향의 소중함을 깨달았다.\n",
      "모델 출력: #명절 #귀국 #가족과함께 #소중한시간 #친구들과함께\n"
     ]
    }
   ],
   "source": [
    "# 테스트할 문장\n",
    "test_sentence = \"명절을 맞아 고향에 돌아와 가족과 함께 보낸 특별하고 따뜻한 하루였다. 가족의 사랑과 고향의 소중함을 깨달았다.\"\n",
    "\n",
    "# 입력 문장을 토큰화하여 인코딩\n",
    "input_ids = tokenizer.encode(test_sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# 모델에 입력 전달하여 디코딩\n",
    "output = model.generate(input_ids)\n",
    "\n",
    "# 디코딩된 출력을 토크나이저를 사용하여 텍스트로 변환\n",
    "decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"입력 문장:\", test_sentence)\n",
    "print(\"모델 출력:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBG0WzY5jMTL"
   },
   "outputs": [],
   "source": [
    "def make_tag(text):\n",
    "  # 입력 문장을 토큰화하여 인코딩\n",
    "  input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "  # 모델에 입력 전달하여 디코딩\n",
    "  output = model.generate(input_ids).to(device)\n",
    "\n",
    "  # 디코딩된 출력을 토크나이저를 사용하여 텍스트로 변환\n",
    "  decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  # 결과 출력\n",
    "  print(\"입력 문장:\", text)\n",
    "  print(\"모델 출력:\", decoded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q44lI3qTseeI",
    "outputId": "22c97a3d-5416-458b-9bf6-a3b85ebed14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 반려동물과 함께 특별한 일상을 기록하며 즐거움과 행복을 느낀 특별한 경험을 한 날이었어.\n",
      "모델 출력: #강아지 #즐거움과행복 #충실한친구 #사랑스러운모습 #\n"
     ]
    }
   ],
   "source": [
    "make_tag(diary.iloc[-2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P22Eri1Nsh_L",
    "outputId": "33a152c5-1d3f-408f-b1ca-e1e43f29d3e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 취업 준비를 하며 부족함과 노력을 돌아보고 성장의 기회를 찾은 특별한 경험을 한 날이었어.\n",
      "모델 출력: #취준생 #취업준비 #부족함과노력 #성장의기회 #\n"
     ]
    }
   ],
   "source": [
    "make_tag(diary.iloc[-10,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9shx2Ig2TP2X",
    "outputId": "f27f6fd3-1e5a-4731-aec1-ab6fe462fcbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문장: 요가를 시작해서 몸과 마음이 편안해지고 건강을 유지하고 있어요.\n",
      "모델 출력: #요가 #건강 #편안함 #유연성 #숨쉬기 #\n"
     ]
    }
   ],
   "source": [
    "make_tag(diary.iloc[-45,1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
